{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This function is used to add two matrices together without exceeding the pixel value of 255.\n",
    "def add_to_255(a, b):\n",
    "    \"\"\"Return a+b to a max value of 255\"\"\"\n",
    "    if a + b > 255:\n",
    "        return 255\n",
    "    else:\n",
    "        return a + b\n",
    "v_add_to_255 = np.vectorize(add_to_255)  # Here we create a \"vectorized\" form of our simple function above.\n",
    "\n",
    "def noisy_line(img, label):\n",
    "    \"\"\"Adds background noise and a vertical line on the right edge to match data\"\"\"\n",
    "    rng = np.random.default_rng()  # This function uses a random number generator, created here.\n",
    "    line = np.zeros((28,28,1), dtype=np.uint8)  # Our line will be defined in a 28x28 matrix, initial set to zeroes.\n",
    "    \n",
    "    # We pick a random number c, from 20 to 25, as the center position of our horizontal line.\n",
    "    c = rng.integers(20, high=25, size=1)[0]  # randomized position of line\n",
    "    a = rng.integers(0, high=100, size=1)[0]  # randomized transparency of line\n",
    "\n",
    "    # We set the center of the line to a max of 200 and adjacent rows to a max of 100.\n",
    "    line[c,:] = (100 - a)\n",
    "    line[c+1,:] = (200 - 2 * a)\n",
    "    line[c+2,:] = (100 - a)\n",
    "    noise = rng.integers(0, high=(100-a),size=(3,28,1))\n",
    "    line[c:c+3,:] = line[c:c+3,:] - noise\n",
    "    img = v_add_to_255(img, line)\n",
    "    return img, label\n",
    "\n",
    "# Some examples of the noise we will add to EMNIST\n",
    "# z = np.zeros((28,28, 1), dtype=np.uint8)\n",
    "# view(noisy_line(z, 0)[0])  # The views show normalized luminence, i.e. they treat the highest value found as white.\n",
    "# view(noisy_line(z, 1)[0])  # This means that our transparency value has no impact in these previews of the noisy lines.\n",
    "# view(noisy_line(z, 2)[0])\n",
    "\n",
    "# # Some examples of EMNIST letters with noise added.\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# for i, (image, label) in enumerate(ds_train_readable.take(9)):\n",
    "#     ax = plt.subplot(3, 3, i + 1)\n",
    "#     #img_numpy = image.numpy()[..., None]  # Adding a dimension to match TF dataset API\n",
    "#     img_numpy = image.numpy()  # Adding a dimension to match TF dataset API\n",
    "#     img, lbl = noisy_line(img_numpy, label.numpy())\n",
    "#     plt.imshow(img)\n",
    "#     plt.title(str(int(lbl)))\n",
    "#     plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='emnist',\n",
      "    full_name='emnist/letters/3.0.0',\n",
      "    description=\"\"\"\n",
      "    The EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19 and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset.\n",
      "    \n",
      "    Note: Like the original EMNIST data, images provided here are inverted horizontally and rotated 90 anti-clockwise. You can use `tf.transpose` within `ds.map` to convert the images to a human-friendlier format.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    EMNIST Letters\n",
      "    \"\"\",\n",
      "    homepage='https://www.nist.gov/itl/products-and-services/emnist-dataset',\n",
      "    data_dir='/home/jansen/tensorflow_datasets/emnist/letters/3.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=535.73 MiB,\n",
      "    dataset_size=44.14 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=14800, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=88800, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{cohen_afshar_tapson_schaik_2017,\n",
      "        title={EMNIST: Extending MNIST to handwritten letters},\n",
      "        DOI={10.1109/ijcnn.2017.7966217},\n",
      "        journal={2017 International Joint Conference on Neural Networks (IJCNN)},\n",
      "        author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Schaik, Andre Van},\n",
      "        year={2017}\n",
      "    }\"\"\",\n",
      ")\n",
      "Examples:\n",
      "    Total: 88800\n",
      "    Positive: 3437 (3.87% of total)\n",
      "\n",
      "Initial bias: [-3.21231375]\n",
      "final element_spec (TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))\n",
      "final test element_spec (TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.int64, name=None))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 12:34:23.303798: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'emnist/letters',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "print(ds_info)\n",
    "\n",
    "# tfds.show_statistics(ds_info) Not working\n",
    "labels, counts = np.unique(np.fromiter(ds_train.map(lambda x, y: y), np.int32), return_counts=True)\n",
    "pos = counts[23]\n",
    "neg = 88800 - pos\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "initial_bias = np.log([pos/neg])\n",
    "print(f'Initial bias: {initial_bias}')\n",
    "\n",
    "ds_train_readable = ds_train.map(\n",
    "  lambda img, label: (tf.transpose(img, perm=[1,0,2]), tf.cast([(label == 23)], tf.int64)),\n",
    "  num_parallel_calls=tf.data.AUTOTUNE,\n",
    "  deterministic=True)\n",
    "\n",
    "ds_train_readable_noisy = ds_train_readable.map(\n",
    "  lambda img, label: tf.numpy_function(func=noisy_line, inp=[img, label], Tout=(tf.uint8, tf.int64)),\n",
    "  num_parallel_calls=tf.data.AUTOTUNE, \n",
    "  deterministic=False)\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "ds_train_readable_noisy_float = ds_train_readable_noisy.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def set_shapes(image, label):\n",
    "  image.set_shape([28, 28, 1])\n",
    "  label.set_shape([1])\n",
    "  return image, label\n",
    "ds_train_final = ds_train_readable_noisy_float.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Some additional dataset setup steps\n",
    "ds_train_final = ds_train_final.cache()\n",
    "ds_train_final = ds_train_final.batch(400)  # This changes the shape of the data, so call it after all mapped functions..\n",
    "ds_train_final = ds_train_final.prefetch(tf.data.AUTOTUNE)\n",
    "print(\"final element_spec\", ds_train_final.element_spec)\n",
    "\n",
    "# Then we need to apply the same functions and settings to the test dataset\n",
    "ds_test_readable = ds_test.map(\n",
    "  lambda img, label: (tf.transpose(img, perm=[1,0,2]), tf.cast([(label == 23)], tf.int64)),\n",
    "  num_parallel_calls=tf.data.AUTOTUNE, \n",
    "  deterministic=True)\n",
    "\n",
    "ds_test_readable_noisy = ds_test_readable.map(\n",
    "  lambda img, label: tf.numpy_function(func=noisy_line, inp=[img, label], Tout=(tf.uint8, tf.int64)),\n",
    "  num_parallel_calls=tf.data.AUTOTUNE, \n",
    "  deterministic=False)\n",
    "ds_test_readable_noisy_float = ds_test_readable_noisy.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test_final = ds_test_readable_noisy_float.map(set_shapes, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test_final = ds_test_final.batch(400)\n",
    "ds_test_final = ds_test_final.cache()\n",
    "ds_test_final = ds_test_final.prefetch(tf.data.AUTOTUNE)\n",
    "print(\"final test element_spec\", ds_test_final.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryCrossentropy(name='cross entropy'),  # same as model's loss\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_dense_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(28,28), name='input'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 12:34:31.427446: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 283ms/step - Brier score: 0.0159 - accuracy: 0.9799 - auc: 0.9582 - cross entropy: 0.0611 - fn: 602.2960 - fp: 186.6143 - loss: 0.0611 - prc: 0.7527 - precision: 0.8222 - recall: 0.5675 - tn: 42896.7188 - tp: 1112.5785 - val_Brier score: 0.0018 - val_accuracy: 0.9982 - val_auc: 0.0000e+00 - val_cross entropy: 0.0097 - val_fn: 0.0000e+00 - val_fp: 26.0000 - val_loss: 0.0097 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14774.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0079 - accuracy: 0.9895 - auc: 0.9913 - cross entropy: 0.0304 - fn: 324.8520 - fp: 124.9910 - loss: 0.0304 - prc: 0.9281 - precision: 0.9115 - recall: 0.7995 - tn: 42958.3398 - tp: 1390.0225 - val_Brier score: 7.9752e-04 - val_accuracy: 0.9995 - val_auc: 0.0000e+00 - val_cross entropy: 0.0053 - val_fn: 0.0000e+00 - val_fp: 8.0000 - val_loss: 0.0053 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14792.0000 - val_tp: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0061 - accuracy: 0.9923 - auc: 0.9939 - cross entropy: 0.0233 - fn: 234.2422 - fp: 92.0179 - loss: 0.0233 - prc: 0.9542 - precision: 0.9359 - recall: 0.8543 - tn: 42991.3125 - tp: 1480.6323 - val_Brier score: 5.0673e-04 - val_accuracy: 0.9995 - val_auc: 0.0000e+00 - val_cross entropy: 0.0036 - val_fn: 0.0000e+00 - val_fp: 8.0000 - val_loss: 0.0036 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14792.0000 - val_tp: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0049 - accuracy: 0.9938 - auc: 0.9954 - cross entropy: 0.0194 - fn: 195.3812 - fp: 71.4439 - loss: 0.0194 - prc: 0.9663 - precision: 0.9528 - recall: 0.8785 - tn: 43011.8867 - tp: 1519.4933 - val_Brier score: 3.1280e-04 - val_accuracy: 0.9996 - val_auc: 0.0000e+00 - val_cross entropy: 0.0021 - val_fn: 0.0000e+00 - val_fp: 6.0000 - val_loss: 0.0021 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14794.0000 - val_tp: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0043 - accuracy: 0.9944 - auc: 0.9949 - cross entropy: 0.0173 - fn: 173.6771 - fp: 70.4350 - loss: 0.0173 - prc: 0.9727 - precision: 0.9553 - recall: 0.8941 - tn: 43012.8984 - tp: 1541.1973 - val_Brier score: 4.5310e-04 - val_accuracy: 0.9995 - val_auc: 0.0000e+00 - val_cross entropy: 0.0027 - val_fn: 0.0000e+00 - val_fp: 8.0000 - val_loss: 0.0027 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14792.0000 - val_tp: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0040 - accuracy: 0.9948 - auc: 0.9939 - cross entropy: 0.0162 - fn: 158.4978 - fp: 61.0135 - loss: 0.0162 - prc: 0.9732 - precision: 0.9580 - recall: 0.9020 - tn: 43022.3203 - tp: 1556.3767 - val_Brier score: 2.2552e-04 - val_accuracy: 0.9998 - val_auc: 0.0000e+00 - val_cross entropy: 0.0013 - val_fn: 0.0000e+00 - val_fp: 3.0000 - val_loss: 0.0013 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14797.0000 - val_tp: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0037 - accuracy: 0.9955 - auc: 0.9968 - cross entropy: 0.0145 - fn: 136.1211 - fp: 60.1883 - loss: 0.0145 - prc: 0.9797 - precision: 0.9630 - recall: 0.9152 - tn: 43023.1445 - tp: 1578.7534 - val_Brier score: 5.7824e-04 - val_accuracy: 0.9993 - val_auc: 0.0000e+00 - val_cross entropy: 0.0027 - val_fn: 0.0000e+00 - val_fp: 10.0000 - val_loss: 0.0027 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14790.0000 - val_tp: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0033 - accuracy: 0.9959 - auc: 0.9960 - cross entropy: 0.0133 - fn: 120.2197 - fp: 54.1659 - loss: 0.0133 - prc: 0.9822 - precision: 0.9643 - recall: 0.9251 - tn: 43029.1641 - tp: 1594.6547 - val_Brier score: 2.5116e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0014 - val_fn: 0.0000e+00 - val_fp: 5.0000 - val_loss: 0.0014 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14795.0000 - val_tp: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0030 - accuracy: 0.9961 - auc: 0.9959 - cross entropy: 0.0123 - fn: 116.5561 - fp: 51.2511 - loss: 0.0123 - prc: 0.9843 - precision: 0.9685 - recall: 0.9270 - tn: 43032.0820 - tp: 1598.3184 - val_Brier score: 3.3244e-04 - val_accuracy: 0.9995 - val_auc: 0.0000e+00 - val_cross entropy: 0.0016 - val_fn: 0.0000e+00 - val_fp: 7.0000 - val_loss: 0.0016 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14793.0000 - val_tp: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0031 - accuracy: 0.9959 - auc: 0.9964 - cross entropy: 0.0122 - fn: 126.1704 - fp: 49.2422 - loss: 0.0122 - prc: 0.9842 - precision: 0.9700 - recall: 0.9207 - tn: 43034.0898 - tp: 1588.7040 - val_Brier score: 2.0913e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0011 - val_fn: 0.0000e+00 - val_fp: 5.0000 - val_loss: 0.0011 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14795.0000 - val_tp: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0028 - accuracy: 0.9966 - auc: 0.9973 - cross entropy: 0.0112 - fn: 99.0179 - fp: 47.2646 - loss: 0.0112 - prc: 0.9862 - precision: 0.9721 - recall: 0.9369 - tn: 43036.0664 - tp: 1615.8564 - val_Brier score: 3.9886e-04 - val_accuracy: 0.9995 - val_auc: 0.0000e+00 - val_cross entropy: 0.0019 - val_fn: 0.0000e+00 - val_fp: 8.0000 - val_loss: 0.0019 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14792.0000 - val_tp: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0027 - accuracy: 0.9968 - auc: 0.9973 - cross entropy: 0.0110 - fn: 98.5471 - fp: 42.5830 - loss: 0.0110 - prc: 0.9865 - precision: 0.9714 - recall: 0.9415 - tn: 43040.7500 - tp: 1616.3274 - val_Brier score: 2.4228e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0012 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0012 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0024 - accuracy: 0.9971 - auc: 0.9975 - cross entropy: 0.0099 - fn: 91.8969 - fp: 37.0628 - loss: 0.0099 - prc: 0.9878 - precision: 0.9795 - recall: 0.9421 - tn: 43046.2695 - tp: 1622.9775 - val_Brier score: 1.3990e-04 - val_accuracy: 0.9999 - val_auc: 0.0000e+00 - val_cross entropy: 8.5277e-04 - val_fn: 0.0000e+00 - val_fp: 2.0000 - val_loss: 8.5277e-04 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14798.0000 - val_tp: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0026 - accuracy: 0.9967 - auc: 0.9982 - cross entropy: 0.0100 - fn: 102.2197 - fp: 41.6771 - loss: 0.0100 - prc: 0.9891 - precision: 0.9763 - recall: 0.9347 - tn: 43041.6562 - tp: 1612.6547 - val_Brier score: 2.9783e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0014 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0014 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - Brier score: 0.0024 - accuracy: 0.9969 - auc: 0.9977 - cross entropy: 0.0095 - fn: 90.8475 - fp: 38.2915 - loss: 0.0095 - prc: 0.9887 - precision: 0.9743 - recall: 0.9420 - tn: 43045.0391 - tp: 1624.0269 - val_Brier score: 2.4550e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0011 - val_fn: 0.0000e+00 - val_fp: 5.0000 - val_loss: 0.0011 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14795.0000 - val_tp: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7cc3bc1b8550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_model = make_dense_model(output_bias=initial_bias)\n",
    "\n",
    "dense_model.fit(\n",
    "    ds_train_final,BinaryCrossentropy\n",
    "    epochs=15,\n",
    "    validation_data=ds_test_final,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_conv_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = keras.initializers.Constant(output_bias)\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\", bias_initializer=output_bias)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=metrics)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - Brier score: 0.0124 - accuracy: 0.9845 - auc: 0.9712 - cross entropy: 0.0482 - fn: 779.9910 - fp: 166.6861 - loss: 0.0777 - prc: 0.6512 - precision: 0.7519 - recall: 0.4315 - tn: 57716.6445 - tp: 934.8834 - val_Brier score: 8.2666e-04 - val_accuracy: 0.9992 - val_auc: 0.0000e+00 - val_cross entropy: 0.0055 - val_fn: 0.0000e+00 - val_fp: 12.0000 - val_loss: 0.0055 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14788.0000 - val_tp: 0.0000e+00\n",
      "Epoch 2/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - Brier score: 0.0070 - accuracy: 0.9915 - auc: 0.9941 - cross entropy: 0.0265 - fn: 264.6278 - fp: 100.8251 - loss: 0.0265 - prc: 0.9421 - precision: 0.9319 - recall: 0.8359 - tn: 42982.5078 - tp: 1450.2466 - val_Brier score: 6.7269e-04 - val_accuracy: 0.9993 - val_auc: 0.0000e+00 - val_cross entropy: 0.0042 - val_fn: 0.0000e+00 - val_fp: 11.0000 - val_loss: 0.0042 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14789.0000 - val_tp: 0.0000e+00\n",
      "Epoch 3/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - Brier score: 0.0052 - accuracy: 0.9933 - auc: 0.9952 - cross entropy: 0.0195 - fn: 198.6771 - fp: 90.4664 - loss: 0.0195 - prc: 0.9657 - precision: 0.9372 - recall: 0.8801 - tn: 42992.8672 - tp: 1516.1973 - val_Brier score: 3.6745e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0024 - val_fn: 0.0000e+00 - val_fp: 5.0000 - val_loss: 0.0024 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14795.0000 - val_tp: 0.0000e+00\n",
      "Epoch 4/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - Brier score: 0.0044 - accuracy: 0.9944 - auc: 0.9969 - cross entropy: 0.0168 - fn: 167.4126 - fp: 75.0045 - loss: 0.0168 - prc: 0.9727 - precision: 0.9515 - recall: 0.8985 - tn: 43008.3281 - tp: 1547.4619 - val_Brier score: 3.8250e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0024 - val_fn: 0.0000e+00 - val_fp: 5.0000 - val_loss: 0.0024 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14795.0000 - val_tp: 0.0000e+00\n",
      "Epoch 5/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - Brier score: 0.0039 - accuracy: 0.9951 - auc: 0.9965 - cross entropy: 0.0156 - fn: 142.9596 - fp: 71.1570 - loss: 0.0156 - prc: 0.9759 - precision: 0.9535 - recall: 0.9141 - tn: 43012.1758 - tp: 1571.9148 - val_Brier score: 2.4161e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0016 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0016 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 6/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - Brier score: 0.0038 - accuracy: 0.9952 - auc: 0.9962 - cross entropy: 0.0151 - fn: 143.0583 - fp: 73.0717 - loss: 0.0151 - prc: 0.9771 - precision: 0.9564 - recall: 0.9161 - tn: 43010.2617 - tp: 1571.8162 - val_Brier score: 2.3186e-04 - val_accuracy: 0.9998 - val_auc: 0.0000e+00 - val_cross entropy: 0.0015 - val_fn: 0.0000e+00 - val_fp: 3.0000 - val_loss: 0.0015 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14797.0000 - val_tp: 0.0000e+00\n",
      "Epoch 7/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - Brier score: 0.0034 - accuracy: 0.9956 - auc: 0.9957 - cross entropy: 0.0135 - fn: 127.9776 - fp: 63.9238 - loss: 0.0135 - prc: 0.9802 - precision: 0.9585 - recall: 0.9227 - tn: 43019.4062 - tp: 1586.8969 - val_Brier score: 1.8987e-04 - val_accuracy: 0.9998 - val_auc: 0.0000e+00 - val_cross entropy: 0.0012 - val_fn: 0.0000e+00 - val_fp: 3.0000 - val_loss: 0.0012 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14797.0000 - val_tp: 0.0000e+00\n",
      "Epoch 8/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - Brier score: 0.0031 - accuracy: 0.9962 - auc: 0.9964 - cross entropy: 0.0125 - fn: 112.7040 - fp: 55.2197 - loss: 0.0125 - prc: 0.9826 - precision: 0.9655 - recall: 0.9320 - tn: 43028.1133 - tp: 1602.1704 - val_Brier score: 1.2847e-04 - val_accuracy: 0.9998 - val_auc: 0.0000e+00 - val_cross entropy: 8.5364e-04 - val_fn: 0.0000e+00 - val_fp: 3.0000 - val_loss: 8.5364e-04 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14797.0000 - val_tp: 0.0000e+00\n",
      "Epoch 9/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - Brier score: 0.0030 - accuracy: 0.9963 - auc: 0.9969 - cross entropy: 0.0123 - fn: 107.7444 - fp: 54.1614 - loss: 0.0123 - prc: 0.9835 - precision: 0.9675 - recall: 0.9319 - tn: 43029.1719 - tp: 1607.1300 - val_Brier score: 2.0169e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0012 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0012 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 10/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - Brier score: 0.0030 - accuracy: 0.9962 - auc: 0.9958 - cross entropy: 0.0121 - fn: 108.2556 - fp: 53.6233 - loss: 0.0121 - prc: 0.9824 - precision: 0.9636 - recall: 0.9351 - tn: 43029.7070 - tp: 1606.6188 - val_Brier score: 3.6740e-04 - val_accuracy: 0.9996 - val_auc: 0.0000e+00 - val_cross entropy: 0.0019 - val_fn: 0.0000e+00 - val_fp: 6.0000 - val_loss: 0.0019 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14794.0000 - val_tp: 0.0000e+00\n",
      "Epoch 11/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - Brier score: 0.0026 - accuracy: 0.9967 - auc: 0.9965 - cross entropy: 0.0109 - fn: 95.8072 - fp: 47.2825 - loss: 0.0109 - prc: 0.9850 - precision: 0.9693 - recall: 0.9427 - tn: 43036.0508 - tp: 1619.0673 - val_Brier score: 3.8529e-04 - val_accuracy: 0.9996 - val_auc: 0.0000e+00 - val_cross entropy: 0.0019 - val_fn: 0.0000e+00 - val_fp: 6.0000 - val_loss: 0.0019 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14794.0000 - val_tp: 0.0000e+00\n",
      "Epoch 12/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - Brier score: 0.0025 - accuracy: 0.9968 - auc: 0.9963 - cross entropy: 0.0106 - fn: 90.1345 - fp: 45.9193 - loss: 0.0106 - prc: 0.9861 - precision: 0.9711 - recall: 0.9444 - tn: 43037.4141 - tp: 1624.7399 - val_Brier score: 1.9146e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0010 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0010 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 13/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - Brier score: 0.0023 - accuracy: 0.9972 - auc: 0.9963 - cross entropy: 0.0100 - fn: 85.9776 - fp: 41.8969 - loss: 0.0100 - prc: 0.9867 - precision: 0.9748 - recall: 0.9494 - tn: 43041.4336 - tp: 1628.8969 - val_Brier score: 1.6913e-04 - val_accuracy: 0.9998 - val_auc: 0.0000e+00 - val_cross entropy: 9.1457e-04 - val_fn: 0.0000e+00 - val_fp: 3.0000 - val_loss: 9.1457e-04 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14797.0000 - val_tp: 0.0000e+00\n",
      "Epoch 14/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - Brier score: 0.0024 - accuracy: 0.9971 - auc: 0.9978 - cross entropy: 0.0098 - fn: 74.0269 - fp: 48.2287 - loss: 0.0098 - prc: 0.9881 - precision: 0.9674 - recall: 0.9540 - tn: 43035.1016 - tp: 1640.8475 - val_Brier score: 2.2988e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0012 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0012 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n",
      "Epoch 15/15\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - Brier score: 0.0023 - accuracy: 0.9971 - auc: 0.9981 - cross entropy: 0.0092 - fn: 77.8251 - fp: 46.4574 - loss: 0.0092 - prc: 0.9897 - precision: 0.9696 - recall: 0.9544 - tn: 43036.8750 - tp: 1637.0493 - val_Brier score: 2.0969e-04 - val_accuracy: 0.9997 - val_auc: 0.0000e+00 - val_cross entropy: 0.0010 - val_fn: 0.0000e+00 - val_fp: 4.0000 - val_loss: 0.0010 - val_prc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 14796.0000 - val_tp: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7cc3e2d8b3a0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model = make_conv_model(output_bias=initial_bias)\n",
    "conv_model.fit(\n",
    "    ds_train_final,\n",
    "    epochs=15,\n",
    "    validation_data=ds_test_final,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.save(\"dense_model_2.keras\", overwrite=True)\n",
    "conv_model.save(\"conv_model_2.keras\", overwrite=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
